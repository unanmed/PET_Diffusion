import argparse
import os
from scipy import io
import torch
import numpy as np
import cv2
from tqdm import tqdm
from model.model import PETUNet
from model.loss import MSESSIMLoss

def parse_arguments():
    parser = argparse.ArgumentParser(description="training codes")
    parser.add_argument("--output", type=str, default="../results/model_default", help="Path to save checkpoint.")
    parser.add_argument("--input", type=str, default="../mat/NAC_test", help="Input images.")
    parser.add_argument("--target", type=str, default="../mat/CTAC_test", help="Target images.")
    parser.add_argument("--model", type=str, default="../models/model_default/checkpoint/latest.pth")
    args = parser.parse_args()
    return args

def init_status(args):
    os.makedirs(args.output, exist_ok=True)
    os.makedirs(os.path.join(args.output, "predict"), exist_ok=True)
    os.makedirs(os.path.join(args.output, "target"), exist_ok=True)
    os.makedirs(os.path.join(args.output, "origin"), exist_ok=True)
    
def process_image(img):
    img = np.expand_dims(img, axis=0)
    img = torch.from_numpy(img).unsqueeze(0).float()
    return img

def eval(args):
    # ğŸ§  2. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡
    model = PETUNet()
    # åŠ è½½æ¨¡å‹æƒé‡å­—å…¸
    checkpoint = torch.load(args.model, map_location='cpu')
    criterion = MSESSIMLoss()
    
    # å¤„ç† state_dictï¼Œç§»é™¤ 'module.' å‰ç¼€
    new_state_dict = {}
    for k, v in checkpoint.items():
        if k.startswith('module.'):
            new_state_dict[k[7:]] = v  # å»æ‰ 'module.' å‰ç¼€
        else:
            new_state_dict[k] = v

    # å°†æ–° state_dict åŠ è½½åˆ°æ¨¡å‹ä¸­
    model.load_state_dict(new_state_dict)
    model.eval()  # è®¾ä¸ºæ¨ç†æ¨¡å¼
    
    input_folder = args.input  # å­˜æ”¾ .mat æ–‡ä»¶çš„æ–‡ä»¶å¤¹
    target_folder = args.target  # æœŸæœ›è¾“å‡ºå›¾ç‰‡
    output_folder = args.output  # é¢„æµ‹è¾“å‡ºå›¾ç‰‡çš„ä¿å­˜æ–‡ä»¶å¤¹
    
    loss_total = 0
    
    for file_name in tqdm(os.listdir(input_folder)):
        input_path = os.path.join(input_folder, file_name)
        target_path = os.path.join(target_folder, file_name)
        
        # è¯»å– .mat æ–‡ä»¶ä¸­çš„å›¾åƒæ•°æ® (å‡è®¾ img å­—æ®µåŒ…å« 256x256 çš„ç°åº¦å›¾ï¼ŒèŒƒå›´ä¸º 0-1)
        input_img = io.loadmat(input_path)['img'].astype('float32')
        input_img = process_image(input_img)
        
        target_img = io.loadmat(target_path)['img'].astype('float32')
        target_img = process_image(target_img)
        
        # è¿›è¡Œæ¨ç†
        with torch.no_grad():
            output = model(input_img)
            
        loss = criterion(output, target_img)
        loss_total += loss
        
        # å¤„ç†è¾“å‡º (è½¬æ¢ä¸ºå›¾åƒ)
        output = output.squeeze(0).squeeze(0).numpy()  # å½¢çŠ¶ (224, 224)
        output = (output - output.min()) / (output.max() - output.min())  # å½’ä¸€åŒ–åˆ° 0-1
        output = (output * 255).astype(np.uint8)
        
        # ä¿å­˜è¾“å‡ºå›¾åƒ
        output_path = os.path.join(output_folder, "predict", f"{os.path.splitext(file_name)[0]}.png")
        cv2.imwrite(output_path, output)
        
    print(f"All precessed loss: {loss_total / len(os.listdir(input_folder))}")

if __name__ == "__main__":
    args = parse_arguments()
    init_status(args)
    eval(args)