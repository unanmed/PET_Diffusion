import argparse
import os
from scipy import io
import torch
import numpy as np
import cv2
from train import PETUNet

def generate_mask(img_height, img_width, radius, center_x, center_y):
    y, x = np.ogrid[0:img_height, 0:img_width]
    # circle mask
    mask = (x - center_x) ** 2 + (y - center_y) ** 2 <= radius ** 2
    return mask

def parse_arguments():
    parser = argparse.ArgumentParser(description="training codes")
    parser.add_argument("--output", type=str, default="../results/model_default", help="Path to save checkpoint.")
    parser.add_argument("--input", type=str, default="../mat/NAC_train", help="Input images.")
    parser.add_argument("--target", type=str, default="../mat/CT_train", help="Target images.")
    parser.add_argument("--model", type=str, default="../models/model_default/checkpoint/latest.pth")
    args = parser.parse_args()
    return args

def init_status(args):
    os.makedirs(args.output, exist_ok=True)
    os.makedirs(os.path.join(args.output, "predict"), exist_ok=True)
    os.makedirs(os.path.join(args.output, "target"), exist_ok=True)
    os.makedirs(os.path.join(args.output, "origin"), exist_ok=True)

def eval(args):
    # ðŸ§  2. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡åž‹æƒé‡
    model = PETUNet()
    # åŠ è½½æ¨¡åž‹æƒé‡å­—å…¸
    checkpoint = torch.load(args.model, map_location='cpu')

    # å¤„ç† state_dictï¼Œç§»é™¤ 'module.' å‰ç¼€
    new_state_dict = {}
    for k, v in checkpoint.items():
        if k.startswith('module.'):
            new_state_dict[k[7:]] = v  # åŽ»æŽ‰ 'module.' å‰ç¼€
        else:
            new_state_dict[k] = v

    # å°†æ–° state_dict åŠ è½½åˆ°æ¨¡åž‹ä¸­
    model.load_state_dict(new_state_dict)
    model.eval()  # è®¾ä¸ºæŽ¨ç†æ¨¡å¼
    
    input_folder = args.input  # å­˜æ”¾ .mat æ–‡ä»¶çš„æ–‡ä»¶å¤¹
    target_folder = args.target  # æœŸæœ›è¾“å‡ºå›¾ç‰‡
    output_folder = args.output  # é¢„æµ‹è¾“å‡ºå›¾ç‰‡çš„ä¿å­˜æ–‡ä»¶å¤¹
    
    for file_name in os.listdir(input_folder):
        input_path = os.path.join(input_folder, file_name)
        
        # è¯»å– .mat æ–‡ä»¶ä¸­çš„å›¾åƒæ•°æ® (å‡è®¾ img å­—æ®µåŒ…å« 256x256 çš„ç°åº¦å›¾ï¼ŒèŒƒå›´ä¸º 0-1)
        input_img = io.loadmat(input_path)['img'].astype('float32')
        input_img = np.expand_dims(input_img, axis=0)
        input_img = torch.from_numpy(input_img).unsqueeze(0).float()
        
        # è¿›è¡ŒæŽ¨ç†
        with torch.no_grad():
            output = model(input_img)
        
        # å¤„ç†è¾“å‡º (è½¬æ¢ä¸ºå›¾åƒ)
        output = output.squeeze(0).squeeze(0).numpy()  # å½¢çŠ¶ (224, 224)
        output = (output - output.min()) / (output.max() - output.min())  # å½’ä¸€åŒ–åˆ° 0-1
        output = (output * 255).astype(np.uint8)
        
        # ä¿å­˜è¾“å‡ºå›¾åƒ
        output_path = os.path.join(output_folder, "predict", f"{os.path.splitext(file_name)[0]}.png")
        cv2.imwrite(output_path, output)
        
        print(f"å¤„ç†å®Œæˆ: {file_name} -> {output_path}")

if __name__ == "__main__":
    args = parse_arguments()
    init_status(args)
    eval(args)